import requests
import json
import re
import base64
from copy import deepcopy

# ================= é…ç½® =================

BASE_URL = "http://www.é¥­å¤ªç¡¬.com/tv"
EXTRA_SOURCES = [
    "https://raw.githubusercontent.com/yoursmile66/TVBox/main/XC.json",
    "https://raw.githubusercontent.com/guot55/YGBH/main/vip2.json",
]

OUTPUT_FILE = "my_tvbox.json"
TIMEOUT = 15

HEADERS = {
    "User-Agent": "Mozilla/5.0 (TVBox Fusion)"
}

# ================= è§£ç ï¼ˆå…³é”®ï¼‰ =================

def decode_content(text: str):
    if not text:
        return None
    text = text.strip()

    # 1. ç›´æ¥ JSON
    try:
        return json.loads(text)
    except:
        pass

    # 2. Base64 JSON
    try:
        cleaned = re.sub(r'[^A-Za-z0-9+/=]', '', text)
        decoded = base64.b64decode(cleaned).decode("utf-8")
        return json.loads(decoded)
    except:
        pass

    # 3. æ­£åˆ™æå–
    try:
        m = re.search(r'\{[\s\S]*\}', text)
        if m:
            return json.loads(m.group())
    except:
        pass

    return None


def fetch_json(url):
    try:
        r = requests.get(url, headers=HEADERS, timeout=TIMEOUT)
        r.raise_for_status()
        data = decode_content(r.text)
        if not data:
            print(f"[è·³è¿‡] æ— æ³•è§£æ: {url}")
            return None
        return data
    except Exception as e:
        print(f"[è·³è¿‡] è¯·æ±‚å¤±è´¥: {url} -> {e}")
        return None


# ================= æ ¡éªŒä¸ä¿®å¤ =================

def is_valid_site(site):
    if not isinstance(site, dict):
        return False
    for k in ("key", "name", "api", "type"):
        if k not in site:
            return False
    if not isinstance(site["api"], str):
        return False
    if not site["api"].startswith("http"):
        return False
    return True


def fix_search(site):
    site.setdefault("searchable", 1)
    site.setdefault("quickSearch", 1)
    return site


# ================= ä¸»é€»è¾‘ =================

def main():
    print(">>> æ‹‰å–é¥­å¤ªç¡¬åº•æ¿")
    base = fetch_json(BASE_URL)

    if not base or not isinstance(base, dict):
        print("[è‡´å‘½] é¥­å¤ªç¡¬ä¸å¯è§£æï¼Œç”Ÿæˆå…œåº•æ–‡ä»¶")
        base = {
            "sites": [],
            "parses": [],
            "rules": [],
            "lives": []
        }

    result = deepcopy(base)
    result.setdefault("sites", [])
    result.setdefault("parses", [])
    result.setdefault("rules", [])
    result.setdefault("lives", [])

    print(f"âœ” é¥­å¤ªç¡¬ç«™ç‚¹æ•°: {len(result['sites'])}")

    # è®°å½•å·²æœ‰ keyï¼ˆåªç”¨äºé™„åŠ æºå»é‡ï¼‰
    existing_keys = {s.get("key") for s in result["sites"] if isinstance(s, dict)}

    # ä¿®å¤é¥­å¤ªç¡¬æœç´¢å­—æ®µï¼ˆä¸ç ´åï¼‰
    result["sites"] = [fix_search(s) for s in result["sites"]]

    added = 0

    print(">>> å¼€å§‹èåˆé™„åŠ æº")
    for src in EXTRA_SOURCES:
        print(f"  -> {src}")
        data = fetch_json(src)
        if not data or "sites" not in data:
            continue

        for site in data["sites"]:
            if not is_valid_site(site):
                continue
            if site["key"] in existing_keys:
                continue

            result["sites"].append(fix_search(site))
            existing_keys.add(site["key"])
            added += 1

    print(f"âœ” æ–°å¢èåˆç«™ç‚¹: {added}")
    print(f"ğŸ“Š æœ€ç»ˆç«™ç‚¹æ€»æ•°: {len(result['sites'])}")

    # ä¸€å®šå†™æ–‡ä»¶ï¼Œä¿è¯ CI
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"âœ… è¾“å‡ºå®Œæˆ: {OUTPUT_FILE}")


if __name__ == "__main__":
    main()