import requests
import json
import re
import concurrent.futures
import os
import sys
import base64
from urllib.parse import quote, urljoin

# ================= 1. é…ç½®åŒºåŸŸ =================

# ã€æ ¸å¿ƒé…ç½®ã€‘
# æœ€ç»ˆç”Ÿæˆçš„ JSON é‡Œï¼ŒSpider æŒ‡å‘é¥­å¤ªç¡¬å®˜æ–¹ Jar (æœ€ç¨³å®šï¼Œä¸æä»£ç†äº†)
FINAL_SPIDER_URL = "http://www.é¥­å¤ªç¡¬.com/To/jar/3.jar"
FINAL_WALLPAPER = "https://api.kdcc.cn"

# ã€æŠ“å–ä¸“ç”¨åœ°å€ã€‘
# GitHub æŠ“ä¸åˆ° www.é¥­å¤ªç¡¬.comï¼Œå¿…é¡»ç”¨ fty.xxooo.cf è¿™ä¸ªé•œåƒæ¥æŠ“
PRIME_SOURCE_URL = "http://fty.xxooo.cf/tv"

# ã€è¡¥å……æºåˆ—è¡¨ã€‘(åªæŠ“å–é€šç”¨æ¥å£ï¼Œå¹¶å»ç½‘ç›˜)
EXTERNAL_URLS = [
    # ä¼˜è´¨å¤§å‚ (GitHub é•œåƒï¼Œé€Ÿåº¦å¿«)
    "https://raw.githubusercontent.com/yoursmile66/TVBox/main/XC.json",
    "https://raw.githubusercontent.com/guot55/YGBH/main/vip2.json",
    "https://raw.githubusercontent.com/chitue/dongliTV/main/api.json",
    "https://raw.githubusercontent.com/2hacc/TVBox/main/tvbox.json",
    
    # ä¼˜è´¨èšåˆ
    "https://cdn.jsdelivr.net/gh/2hacc/TVBox@main/tvbox.json",
    "https://cdn.gitmirror.com/bb/xduo/libs/master/index.json",
    "https://raw.githubusercontent.com/gaotianliuyun/gao/master/js.json",
    
    # å¤‡ç”¨
    "https://cnb.cool/fish2018/duanju/-/git/raw/main/tvbox.json",
    "https://tv.èœå¦®ä¸.top",
    "https://api.hgyx.vip/hgyx.json"
]

# ã€è¿‡æ»¤é…ç½®ã€‘
ALLOWED_TYPES = [0, 1, 3, 4] 

# ã€é»‘åå•ã€‘(å¹¿å‘Š/åƒåœ¾)
BLACKLIST = [
    "å¤±æ•ˆ", "æµ‹è¯•", "å¹¿å‘Š", "æ”¶è´¹", "ç¾¤", "åŠ V", "æŒ‚å£", "Qç¾¤", "ä¼¦ç†", "ç¦åˆ©", "æˆäºº", "æƒ…è‰²", 
    "å¼•æµ", "æ›´æ–°", "æ‰«ç ", "å¾®ä¿¡", "ä¼é¹…", "APP", "ä¸‹è½½", "æ¨å¹¿", "éªŒè¯", "æ¿€æ´»", "æˆæƒ", 
    "é›·é²¸", "ç©å¶å“¥å“¥", "åŠ©æ‰‹", "ä¸“çº¿", "å½©è›‹", "ç›´æ’­", "77.110", "mingming"
]

# ã€ç½‘ç›˜ç‰¹å¾ã€‘(ç”¨äºè¿‡æ»¤å¤–éƒ¨æºçš„ç½‘ç›˜)
DISK_KEYWORDS = ["é˜¿é‡Œäº‘", "å¤¸å…‹", "UCç½‘ç›˜", "115", "ç½‘ç›˜", "äº‘ç›˜", "æ¨é€", "å­˜å‚¨", "Drive", "Ali", "Quark"]

TIMEOUT = 20       
MAX_WORKERS = 30   

# ================= 2. å·¥å…·å‡½æ•° =================

def decode_content(content):
    if not content: return None
    try: return json.loads(content)
    except: pass
    try:
        clean = content.replace('**', '').replace('o', '').strip()
        return json.loads(base64.b64decode(clean).decode('utf-8'))
    except:
        try:
            match = re.search(r'\{.*\}', content, re.DOTALL)
            if match: return json.loads(match.group())
        except: pass
    return None

def get_json(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=TIMEOUT, verify=False)
        res.encoding = 'utf-8'
        if res.status_code == 200:
            return decode_content(res.text)
    except: pass
    return None

def clean_name(name):
    name = str(name)
    name = re.sub(r'ã€.*?ã€‘|\[.*?\]|\(.*?\)|ï¼ˆ.*?ï¼‰', '', name)
    name = name.replace("èšåˆ", "").replace("è“å…‰", "").replace("ä¸“çº¿", "").strip()
    return name

# ================= 3. æ ¸å¿ƒå¤„ç†é€»è¾‘ =================

def fetch_and_process(url, is_prime=False):
    print(f"    -> æ­£åœ¨æŠ“å–: {url} ({'å®¿ä¸»' if is_prime else 'æ‰©å±•'})")
    data = get_json(url)
    if not data: 
        print(f"       [!] å¤±è´¥: {url}")
        return []
    
    extracted_sites = []
    
    def process_site(site):
        # 1. å¼ºåˆ¶å‰¥ç¦» Jar (æ ¸å¿ƒé˜²å´©)
        if 'jar' in site:
            del site['jar']
            
        name = site.get('name', '')
        api = str(site.get('api', ''))
        
        # 2. å¦‚æœæ˜¯å®¿ä¸» (é¥­å¤ªç¡¬)ï¼Œæ— æ¡ä»¶ä¿ç•™ (é™¤äº†æ˜æ˜¾çš„å¹¿å‘Š)
        if is_prime:
            if "å¤±æ•ˆ" in name or "æµ‹è¯•" in name: return None
            site['name'] = clean_name(name) # ä»…ç¾åŒ–åå­—
            site['searchable'] = 1
            site['quickSearch'] = 1
            # ç»™å®¿ä¸»æ‰“æ ‡
            if site.get('type') == 3:
                site['name'] = f"ğŸ›¡ï¸ {site['name']}"
            else:
                site['name'] = f"â˜˜ï¸ {site['name']}"
            return site

        # 3. å¦‚æœæ˜¯å¤–éƒ¨æºï¼Œæ‰§è¡Œä¸¥æ ¼è¿‡æ»¤
        # 3.1 å¹¿å‘Šè¿‡æ»¤
        if any(bw in name for bw in BLACKLIST): return None
        if any(char in name for char in ['ğŸ’°', 'ğŸ‘—', 'ğŸ‘ ', 'âœ¨', 'âš¡', 'ğŸ”¥', 'å…è´¹', 'é€', 'åŠ V']): return None
        
        # 3.2 ç½‘ç›˜è¿‡æ»¤ (å¤–éƒ¨æºä¸è¦ç½‘ç›˜)
        is_disk = False
        if any(k in name for k in ["é˜¿é‡Œäº‘", "å¤¸å…‹", "UCç½‘ç›˜", "115", "ç½‘ç›˜", "æ¨é€"]): is_disk = True
        if not is_disk:
            api_lower = api.lower()
            if "ali" in api_lower or "quark" in api_lower or "ucpan" in api_lower or "115.com" in api_lower or "drive" in api_lower:
                is_disk = True
        if is_disk: return None
        
        # 3.3 ç¾åŒ–
        site['name'] = f"ğŸš€ {clean_name(name)}"
        site['searchable'] = 1 
        site['quickSearch'] = 1
        
        return site

    # æå–å¤šä»“
    if 'urls' in data and isinstance(data['urls'], list):
        for item in data['urls']:
            if 'url' in item:
                sub_data = get_json(item['url'])
                if sub_data and 'sites' in sub_data:
                    for s in sub_data['sites']:
                        processed = process_site(s)
                        if processed: extracted_sites.append(processed)
    
    # æå–å•ä»“
    if 'sites' in data:
        for s in data['sites']:
            processed = process_site(s)
            if processed: extracted_sites.append(processed)
            
    return extracted_sites

def main():
    try:
        requests.packages.urllib3.disable_warnings()
        print(">>> å¯åŠ¨ TVBox v38.0 (é¥­å¤ªç¡¬å…¨æ”¶å½•+æ‰©å±•å»ç½‘ç›˜)")
        
        all_sites = []
        
        # 1. ä¼˜å…ˆæŠ“å–å®¿ä¸» (é¥­å¤ªç¡¬)
        # å¿…é¡»å•ç‹¬æŠ“ï¼Œç¡®ä¿å®ƒä¸€å®šåœ¨
        print(">>> [1/3] æŠ“å–å®¿ä¸» (é¥­å¤ªç¡¬)...")
        prime_sites = fetch_and_process(PRIME_SOURCE_URL, is_prime=True)
        if prime_sites:
            print(f"    [âˆš] æˆåŠŸè·å–é¥­å¤ªç¡¬æ¥å£: {len(prime_sites)} ä¸ª")
            all_sites.extend(prime_sites)
        else:
            print("    [!] è­¦å‘Šï¼šæ— æ³•è¿æ¥é¥­å¤ªç¡¬é•œåƒï¼Œå°è¯•è¿æ¥å®˜æ–¹...")
            # å¤‡ç”¨å°è¯•
            prime_sites = fetch_and_process("http://www.é¥­å¤ªç¡¬.com/tv", is_prime=True)
            if prime_sites: all_sites.extend(prime_sites)

        # 2. å¹¶å‘æŠ“å–æ‰©å±•æº
        print(f">>> [2/3] æŠ“å–æ‰©å±•æº ({len(EXTERNAL_URLS)}ä¸ª)...")
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_url = {executor.submit(fetch_and_process, url, False): url for url in EXTERNAL_URLS}
            for future in concurrent.futures.as_completed(future_to_url):
                try:
                    sites = future.result()
                    if sites: all_sites.extend(sites)
                except: pass
        
        # 3. å»é‡ä¸ç”Ÿæˆ
        print(f">>> [3/3] å»é‡ä¸æ‰“åŒ…...")
        unique_sites = []
        seen_api = set()
        
        # æ­¤æ—¶ all_sites é‡Œé¥­å¤ªç¡¬å·²ç»åœ¨æœ€å‰é¢äº†
        for s in all_sites:
            api = s.get('api', '')
            if api and api not in seen_api:
                unique_sites.append(s)
                seen_api.add(api)
                
        # æˆªæ–­
        if len(unique_sites) > 300:
            unique_sites = unique_sites[:300]
        
        # ç”Ÿæˆé…ç½®
        config = {
            "spider": FINAL_SPIDER_URL, # å®˜æ–¹Jar
            "wallpaper": WALLPAPER_URL,
            "sites": unique_sites,
            "lives": [],
            "parses": [],
            "flags": []
        }
        
        with open("my_tvbox.json", 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
            
        print(f"\nâœ… å®Œæˆï¼")
        print(f"ğŸ“Š æ€»è®¡æ¥å£: {len(unique_sites)} ä¸ª")
        print(f"ğŸ›¡ï¸ æ ¸å¿ƒ Jar: {FINAL_SPIDER_URL}")
        
    except Exception as e:
        print(f"\n[!!!] é”™è¯¯: {e}")
        if not os.path.exists("my_tvbox.json"):
            with open("my_tvbox.json", 'w', encoding='utf-8') as f:
                json.dump({"spider":FINAL_SPIDER_URL, "sites":[]}, f)
        sys.exit(0)

if __name__ == "__main__":
    main()
